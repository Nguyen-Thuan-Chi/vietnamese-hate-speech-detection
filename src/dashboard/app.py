# src/dashboard/app.py
import streamlit as st
import pandas as pd
import sys
from pathlib import Path
import plotly.express as px
from typing import Dict, List, Union

# ===== PATH SETUP =====
CURRENT_DIR = Path(__file__).resolve().parent
ROOT_DIR = CURRENT_DIR.parent.parent
sys.path.append(str(ROOT_DIR))

# ===== PAGE CONFIG (PH·∫¢I ·ªû ƒê·∫¶U) =====
st.set_page_config(
    page_title="ViHOS Admin Panel",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== LOAD MODEL (HF SPACE ‚Äì CPU ONLY) =====
@st.cache_resource
def load_model():
    try:
        from src.services.predictor import HateSpeechPredictor
        model_path = ROOT_DIR / "models" / "phobert_epoch_3.pth"
        return HateSpeechPredictor(str(model_path), device="cpu")
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng load ƒë∆∞·ª£c model: {e}")
        st.stop()

predictor = load_model()

# ===== LOAD SERVICES =====
from src.services.highlighter import ToxicHighlighter, KeywordHighlighter
from src.services.feedback import FeedbackManager
from src.services.explainer import LimeTextExplainerService, create_predict_proba_wrapper

highlighter = ToxicHighlighter()
keyword_highlighter = KeywordHighlighter()
feedback_manager = FeedbackManager(ROOT_DIR / "data" / "feedback.csv")

# ===== LIME EXPLAINER (XAI) =====
@st.cache_resource
def load_explainer():
    return LimeTextExplainerService()

lime_explainer = load_explainer()

# Minimum word count threshold for LIME explanation
MIN_WORDS_FOR_LIME = 5

# ===== HELPER FUNCTIONS =====
def predict_text_local(text: str) -> Dict[str, Union[str, List[Dict[str, Union[int, str]]]]]:
    """
    Predict hate speech classification.

    Note: Current model is sentence-level only. The 'spans' field will always
    be empty. UI uses keyword-based fallback for highlighting toxic content.

    Returns dict with:
        - label: "TOXIC" or "CLEAN"
        - confidence: confidence percentage string
        - spans: Always empty (sentence-level model)
    """
    return predictor.predict(text)

def predict_csv_local(df: pd.DataFrame, text_col: str):
    results = []
    for _, row in df.iterrows():
        try:
            res = predictor.predict(str(row[text_col]))
            results.append({
                **row,
                "Label": res["label"],
                "Confidence": res["confidence"]
            })
        except Exception:
            results.append({
                **row,
                "Label": "ERROR",
                "Confidence": "0%"
            })
    return pd.DataFrame(results)

# ===== SIDEBAR =====
with st.sidebar:
    st.title("üõ°Ô∏è ViHOS Control")
    st.markdown("---")
    st.success("üü¢ Model Online (CPU)")
    st.markdown("---")
    menu = st.radio("Menu", ["Dashboard & Live Scan", "Batch File Scanner"])
    st.markdown("---")
    st.info("Running on Hugging Face Spaces")

# ===== MAIN UI =====
if menu == "Dashboard & Live Scan":
    st.header("üì° Live Monitoring Console")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Ki·ªÉm tra nhanh (Quick Test)")
        input_text = st.text_area(
            "Nh·∫≠p n·ªôi dung c·∫ßn ki·ªÉm duy·ªát:",
            height=150,
            placeholder="V√≠ d·ª•: M√†y ngu qu√°..."
        )

        if st.button("Qu√©t ngay (Scan)", type="primary"):
            if not input_text.strip():
                st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung!")
            else:
                with st.spinner("AI ƒëang ph√¢n t√≠ch..."):
                    result = predict_text_local(input_text)
                    # Store result in session state for feedback
                    st.session_state["last_prediction"] = {
                        "text": input_text,
                        "result": result
                    }

                if result.get("label") == "TOXIC":
                    st.error("‚ùå PH√ÅT HI·ªÜN ƒê·ªòC H·∫†I (TOXIC)")
                else:
                    st.success("‚úÖ N·ªòI DUNG S·∫†CH (CLEAN)")

                # Display highlighted text with toxic spans
                spans = result.get("spans", [])
                label = result.get("label", "CLEAN")

                if label == "TOXIC":
                    # Keyword-based highlighting (sentence-level model has no span data)
                    st.markdown("**T·ª´ kh√≥a ƒë√°ng ng·ªù ƒë∆∞·ª£c ƒë√°nh d·∫•u:**")
                    highlighted_html = keyword_highlighter.highlight(input_text)
                    st.markdown(highlighted_html, unsafe_allow_html=True)
                    st.caption(
                        "‚ö†Ô∏è *L∆∞u √Ω: Model ph√¢n lo·∫°i ·ªü c·∫•p ƒë·ªô c√¢u, kh√¥ng x√°c ƒë·ªãnh ch√≠nh x√°c v·ªã tr√≠ ƒë·ªôc h·∫°i. "
                        "C√°c t·ª´ ƒë∆∞·ª£c ƒë√°nh d·∫•u d·ª±a tr√™n danh s√°ch t·ª´ kh√≥a tham kh·∫£o.*"
                    )

                    # ===== LIME EXPLANATION (XAI) =====
                    st.markdown("---")
                    st.markdown("**üîç Ph√¢n t√≠ch XAI (LIME):**")

                    # Get preprocessed text for word count check
                    clean_text = result.get("text_clean", input_text)
                    word_count = len(clean_text.split())

                    if word_count >= MIN_WORDS_FOR_LIME:
                        with st.spinner("ƒêang ph√¢n t√≠ch nguy√™n nh√¢n d·ª± ƒëo√°n..."):
                            try:
                                predict_proba_fn = create_predict_proba_wrapper(predictor)
                                word_weights = lime_explainer.explain(
                                    text=clean_text,
                                    predict_proba_fn=predict_proba_fn,
                                    num_features=10,
                                    num_samples=500,
                                    label_index=1  # TOXIC
                                )
                            except Exception as e:
                                word_weights = []
                                st.warning(f"L·ªói khi ph√¢n t√≠ch LIME: {e}")

                        if word_weights:
                            # Render bar chart for word contributions
                            df_weights = pd.DataFrame(word_weights)
                            df_weights["color"] = df_weights["weight"].apply(
                                lambda w: "G√≥p ph·∫ßn TOXIC" if w > 0 else "G√≥p ph·∫ßn CLEAN"
                            )
                            fig = px.bar(
                                df_weights,
                                x="weight",
                                y="word",
                                orientation="h",
                                color="color",
                                color_discrete_map={
                                    "G√≥p ph·∫ßn TOXIC": "#ff4b4b",
                                    "G√≥p ph·∫ßn CLEAN": "#21c354"
                                },
                                title="M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng t·ª´ ƒë·∫øn d·ª± ƒëo√°n TOXIC"
                            )
                            fig.update_layout(
                                yaxis=dict(autorange="reversed"),
                                showlegend=True,
                                height=350
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            st.caption(
                                "üìä *Thanh ƒë·ªè: t·ª´ l√†m tƒÉng kh·∫£ nƒÉng TOXIC. "
                                "Thanh xanh: t·ª´ l√†m gi·∫£m kh·∫£ nƒÉng TOXIC.*"
                            )
                        else:
                            st.info(
                                "‚ÑπÔ∏è C√¢u qu√° ng·∫Øn ho·∫∑c qu√° ƒë·ªôc h·∫°i ƒë·ªÉ ph√¢n t√≠ch XAI chi ti·∫øt. "
                                "LIME kh√¥ng th·ªÉ t·∫°o gi·∫£i th√≠ch ·ªïn ƒë·ªãnh cho vƒÉn b·∫£n n√†y."
                            )
                    else:
                        st.info(
                            f"‚ÑπÔ∏è C√¢u qu√° ng·∫Øn ({word_count} t·ª´ < {MIN_WORDS_FOR_LIME} t·ª´) "
                            "ƒë·ªÉ ph√¢n t√≠ch XAI chi ti·∫øt. C·∫ßn √≠t nh·∫•t 5 t·ª´ ƒë·ªÉ LIME ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh."
                        )

                st.json(result)

        # ===== FEEDBACK UI =====
        if "last_prediction" in st.session_state:
            st.markdown("---")
            st.subheader("üìù Ph·∫£n h·ªìi (Feedback)")

            last_pred = st.session_state["last_prediction"]
            pred_text = last_pred["text"]
            pred_result = last_pred["result"]
            pred_spans = pred_result.get("spans", [])

            feedback_col1, feedback_col2 = st.columns(2)

            with feedback_col1:
                if st.button("‚úÖ D·ª± ƒëo√°n ch√≠nh x√°c", key="feedback_correct"):
                    feedback_manager.save_feedback(
                        text=pred_text,
                        spans=pred_spans,
                        user_feedback="correct"
                    )
                    st.success("C·∫£m ∆°n ph·∫£n h·ªìi c·ªßa b·∫°n!")
                    del st.session_state["last_prediction"]
                    st.rerun()

            with feedback_col2:
                if st.button("‚ùå D·ª± ƒëo√°n kh√¥ng ch√≠nh x√°c", key="feedback_incorrect"):
                    st.session_state["show_correction_input"] = True

            # Show correction input if user marked prediction as incorrect
            if st.session_state.get("show_correction_input", False):
                correction_text = st.text_area(
                    "Vui l√≤ng m√¥ t·∫£ l·ªói ho·∫∑c nh·∫≠p ƒëo·∫°n vƒÉn b·∫£n ƒë·ªôc h·∫°i ƒë√∫ng:",
                    placeholder="V√≠ d·ª•: ƒêo·∫°n 'xyz' l√† ƒë·ªôc h·∫°i nh∆∞ng kh√¥ng ƒë∆∞·ª£c ph√°t hi·ªán...",
                    key="correction_input"
                )

                if st.button("G·ª≠i ph·∫£n h·ªìi", key="submit_correction"):
                    if correction_text.strip():
                        feedback_manager.save_feedback(
                            text=pred_text,
                            spans=pred_spans,
                            user_feedback=f"incorrect: {correction_text}"
                        )
                        st.success("C·∫£m ∆°n ph·∫£n h·ªìi chi ti·∫øt c·ªßa b·∫°n!")
                        st.session_state["show_correction_input"] = False
                        del st.session_state["last_prediction"]
                        st.rerun()
                    else:
                        st.warning("Vui l√≤ng nh·∫≠p m√¥ t·∫£ l·ªói!")

    with col2:
        st.subheader("H∆∞·ªõng d·∫´n Sysadmin")
        st.markdown("""
        - **TOXIC:** Hate Speech, Offensive, Ch·ª≠i th·ªÅ
        - **CLEAN:** N·ªôi dung an to√†n
        - **Confidence:** ƒê·ªô tin c·∫≠y c·ªßa model
        """)
        st.markdown("üí° *Confidence < 70% ‚Üí n√™n duy·ªát th·ªß c√¥ng*")

elif menu == "Batch File Scanner":
    st.header("üìÇ Batch Log Scanner")
    st.markdown("Upload file chat (.csv, .xlsx) ƒë·ªÉ qu√©t h√†ng lo·∫°t.")

    uploaded_file = st.file_uploader(
        "Ch·ªçn file d·ªØ li·ªáu",
        type=["csv", "xlsx"]
    )

    if uploaded_file:
        try:
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)

            st.dataframe(df.head())

            text_col = st.selectbox(
                "Ch·ªçn c·ªôt ch·ª©a n·ªôi dung chat:",
                df.columns
            )

            if st.button("B·∫Øt ƒë·∫ßu Qu√©t (Start Batch Job)"):
                with st.spinner(f"ƒêang x·ª≠ l√Ω {len(df)} d√≤ng..."):
                    result_df = predict_csv_local(df, text_col)

                st.success("‚úÖ ƒê√£ x·ª≠ l√Ω xong!")

                c1, c2 = st.columns(2)

                with c1:
                    st.subheader("K·∫øt qu·∫£ chi ti·∫øt")
                    st.dataframe(result_df)

                with c2:
                    st.subheader("Th·ªëng k√™ t·ªâ l·ªá")
                    counts = result_df["Label"].value_counts()
                    fig = px.pie(
                        names=counts.index,
                        values=counts.values,
                        title="T·ª∑ l·ªá N·ªôi dung ƒê·ªôc h·∫°i",
                        color_discrete_map={
                            "TOXIC": "red",
                            "CLEAN": "green",
                            "ERROR": "gray"
                        }
                    )
                    st.plotly_chart(fig, use_container_width=True)

                csv = result_df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    "üì• T·∫£i b√°o c√°o (.csv)",
                    csv,
                    "vihos_report.csv",
                    "text/csv"
                )

        except Exception as e:
            st.error(f"L·ªói x·ª≠ l√Ω file: {e}")
